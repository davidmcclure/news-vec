{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from news_vec.corpus import Corpus\n",
    "\n",
    "from tqdm import tqdm\n",
    "from boltons.iterutils import windowed\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-25 22:05:56,848 | INFO : Reading links.\n",
      "1225511it [00:03, 346304.00it/s]\n",
      "2018-12-25 22:06:02,253 | INFO : Reading headlines.\n",
      "1127502it [00:21, 52856.69it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus('../data/clf-links.json/', '../data/clf-headlines.json/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsf = corpus.sample_all_vs_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dsf.skim(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeadlineDataset<8000/1000/1000>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:00<00:00, 171393.71it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 123700.24it/s]\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for split in ('train', 'test'):\n",
    "    for hl, domain in tqdm(getattr(ds, split)):\n",
    "        rows.append((hl['clf_tokens'], domain, split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows, columns=('tokens', 'domain', 'split'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    ngram_range=(1,3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tv.fit_transform(df[df.split=='train']['tokens'])\n",
    "X_test = tv.transform(df[df.split=='test']['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df[df.split=='train']['domain']\n",
    "y_test = df[df.split=='test']['domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn.com ['olivia newton' 'newton' 'review of' 'weighing' 'vets the claims'\n",
      " 'check team vets' 'check team' 'reality check' 'reality check team'\n",
      " 's reality' 'team vets' 'the claims' 's reality check' 'vets the'\n",
      " 'team vets the' 'cnn s reality' 's most' 'the most dangerous'\n",
      " 'does trump' 'world s most']\n",
      "dailykos.com ['live digest' 'elections live' 'elections live digest' 'digest' 'et'\n",
      " 'daily kos radio' 'is live at' 'radio is live' 'radio is' 'kos radio is'\n",
      " 'kos radio' 'is live' 'and #' 'undocumented immigrants' 'kos elections'\n",
      " 'daily kos elections' 'republicans' 'kos' 'daily kos' 'trumpcare']\n",
      "sputniknews.com ['swedes' 'syria s' 'videos infographics' 'photos videos'\n",
      " 'photos videos infographics' 'radio photos videos' 'infographics'\n",
      " 'radio photos' 'mediterranean' 'daesh terrorists' 'de' 'tehran' 'russia'\n",
      " 'us' '#mln' '$ #mln' 'from syria' 'in syria' 'syria' 'daesh']\n",
      "thehill.com ['not trump' 'oppose gop' 'do anything' 'replacement' 'blue dogs'\n",
      " 'new era of' 'new era' 'a new era' 'senators on' 'trump criticizes'\n",
      " 'trump in #' 'trump' 'dem lawmaker' 'dems introduce bill'\n",
      " 'dems introduce' 'split on' 'gop' 'mueller probe' 'healthcare' 'dem']\n",
      "bloomberg.com ['bitcoin' 'bonds' 'bloomberg' 'emerging' 'things you need' 'five things'\n",
      " 'five things you' 'tesla' 'bond' 'start your' 'start your day'\n",
      " 'to start your' 'to know to' 'know to start' 'know to' 'your day'\n",
      " 'stocks' 'billion' '# billion' '$ # billion']\n",
      "breitbart.com ['rev billy' 'billy graham dies' 'graham dies' 'graham dies at' 'per cent'\n",
      " 'cent' '# per cent' 'background' 'tenure' 'comey is a' 'a gun'\n",
      " 'tommy robinson' 'tommy' 'populist' 'bbc' 'islamic state' 'amnesty'\n",
      " 'alien' 'islamic' 'illegal alien']\n",
      "npr.org ['screen time' 'administration proposes' 'trump administration proposes'\n",
      " 'can learn' 'screen' 'orphan' 'enthusiasm' 'takes over'\n",
      " 'supreme court takes' 'court takes' 'court takes over' 'local elections'\n",
      " 'cease fire' 'cease' 'side of' 'destruction' 'memories' 'poetry'\n",
      " 'of place' 'sense of place']\n",
      "huffingtonpost.com ['is so much' 'much more than' 'photos show the' 'photos show' 'week is'\n",
      " 'bahrain' 'your online' 'why' 'consciousness' 'open letter to' 'scar'\n",
      " 'earth day' 'sum' 'sum up' 'entrepreneurs' 'dating' 'queer' 'why women'\n",
      " 'lgbtq' 'open letter']\n",
      "apnews.com ['power turbines' 'of power turbines' 'fishermen fear forests'\n",
      " 'fishermen fear' 'fishermen' 'forests of' 'forests of power' 'turbines'\n",
      " 'strain' 'cosby s' 'uconn' '# weeks' 'of woman' 'wins $ #' 'to ease'\n",
      " 'know for' 'to know for' 'nkorea' 'hospitalized' '# #']\n",
      "buzzfeed.com ['your' 'can you' 'we ll reveal' 'll reveal' 'that' 'things that'\n",
      " 'll make' 'make you' 'that ll' 'we ll tell' 'll tell' 'll tell you'\n",
      " 'tell you' 'are you' 'which' 'and we' 'we ll' 'and we ll' 'll' 'you']\n",
      "rt.com ['escobar s' 'escobar' 'pablo escobar' 'scottish independence'\n",
      " 'for russia' 'against isis' 'jihadist' 'chief s' 'russian' 'on air'\n",
      " '$ #mn' 'des' 'en' 'que' 'tory' 'footage' 'at us' 'rt' '#mn' 'de']\n",
      "wsj.com ['wsj interview with' 'wsj interview' 'rockefeller' 'are headed'\n",
      " 'to state' 'jobless' 'fed s' 'samsung s' 'more of your' 'algorithm'\n",
      " 'right price' 'health insurers' 'insurers' 'us jobless claims'\n",
      " 'us jobless' 'jobless claims' 'scales' 'wsj' 'ecb' 'fed']\n",
      "nytimes.com ['to make the' 'work for' 's supporters' 'for college' 'pete' 'books'\n",
      " 'nobel literature prize' 'literature' 'nobel literature'\n",
      " 'literature prize' 'comes next' 'what comes next' 'what comes'\n",
      " 'the daily' 'real madrid' 'my #' 'what you need' 'to the daily'\n",
      " 'listen to the' 'recipe']\n",
      "washingtonpost.com ['nunes memo' 'the nunes memo' 'joins the washington' 'economy is'\n",
      " 'post as' 'undermined' 'the numbers' 'newspaper' 'the nationals'\n",
      " 'a secret' 'ryan zinke' 'myths about' 'myths' 'mitt' 'mitt romney'\n",
      " 'the washington' 'the washington post' 'president trump s' 'joins the'\n",
      " 'redskins']\n",
      "dailycaller.com ['antivirus' 'obama era' 'reagan' 'clinton email probe' 'clinton email'\n",
      " 'email probe' 'megyn kelly' 'megyn' 'ignored' 'disappointing' 'socialism'\n",
      " 'out with' 'regs' 'in saudi' 'charlie' 'destroying america'\n",
      " 'is destroying america' 'is destroying' 'green energy' 'msnbc']\n",
      "foxnews.com ['become us' 'become us citizens' 'discovered' '# wounded' 'militants'\n",
      " '$ # g' 'california lawmakers' 'others' 'furor over' 'furor' 'shark'\n",
      " 'taco' 'special report with' 'bret' 'with bret' 'with bret baier'\n",
      " 'bret baier' 'report with' 'baier' 'report with bret']\n"
     ]
    }
   ],
   "source": [
    "for d in df.domain.unique():\n",
    "    scores, _ = chi2(X_train, df[df.split=='train']['domain'] == d)\n",
    "    idx = np.argsort(scores)\n",
    "    names = np.array(feature_names)[idx][-20:]\n",
    "    print(d, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   13.0s finished\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs', multi_class='auto', n_jobs=-1, verbose=True)\n",
    "fit = lr.fit(X_train, df[df.split=='train']['domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.226"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
