{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from news_vec.corpus import Corpus\n",
    "\n",
    "from tqdm import tqdm\n",
    "from boltons.iterutils import windowed\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-25 00:25:18,384 | INFO : Reading links.\n",
      "1225511it [00:06, 203771.88it/s]\n",
      "2018-12-25 00:25:27,741 | INFO : Reading headlines.\n",
      "1127502it [00:32, 34874.18it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus('../data/clf-links.json/', '../data/clf-headlines.json/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsf = corpus.sample_a_vs_b('apnews.com', 'buzzfeed.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dsf.skim(6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeadlineDataset<4800/600/600>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4800/4800 [00:00<00:00, 40880.90it/s]\n",
      "100%|██████████| 600/600 [00:00<00:00, 41485.32it/s]\n",
      "100%|██████████| 600/600 [00:00<00:00, 30993.16it/s]\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for hl, domain in tqdm(ds.train):\n",
    "    rows.append((hl['clf_tokens'], domain, 'train'))\n",
    "    \n",
    "for hl, domain in tqdm(ds.val):\n",
    "    rows.append((hl['clf_tokens'], domain, 'val'))\n",
    "    \n",
    "for hl, domain in tqdm(ds.test):\n",
    "    rows.append((hl['clf_tokens'], domain, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows, columns=('tokens', 'domain', 'split'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    ngram_range=(1,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tv.fit_transform(df[df.split=='train']['tokens'])\n",
    "X_val = tv.transform(df[df.split=='val']['tokens'])\n",
    "X_test = tv.transform(df[df.split=='test']['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df[df.split=='train']['domain']\n",
    "y_val = df[df.split=='val']['domain']\n",
    "y_test = df[df.split=='test']['domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apnews.com ['just' 'it' 'these' 'here' 'and we ll' 'is' 'we ll' 'people' 'and we'\n",
      " 'which' 'we' 'll' 'your' 'that' 'this' 'and' 'a' 'are' 'the' 'you']\n",
      "buzzfeed.com ['just' 'it' 'these' 'here' 'and we ll' 'is' 'we ll' 'people' 'and we'\n",
      " 'which' 'we' 'll' 'your' 'that' 'this' 'and' 'a' 'are' 'the' 'you']\n"
     ]
    }
   ],
   "source": [
    "for d in df.domain.unique():\n",
    "    scores, _ = chi2(X_train, df[df.split=='train']['domain'] == d)\n",
    "    idx = np.argsort(scores)\n",
    "    names = np.array(feature_names)[idx][-20:]\n",
    "    print(d, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.3s finished\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs', multi_class='auto', n_jobs=-1, verbose=True)\n",
    "fit = lr.fit(X_train, df[df.split=='train']['domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8883333333333333"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
