{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import gzip\n",
    "import ujson\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "from boltons.iterutils import chunked_iter\n",
    "from itertools import islice, chain\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchtext.vocab import Vocab\n",
    "from torch.nn.utils import rnn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from news_vec.cuda import itype, ftype\n",
    "from news_vec import logger\n",
    "from news_vec.utils import group_by_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_gz_lines(root):\n",
    "    \"\"\"Read JSON corpus.\n",
    "\n",
    "    Yields: Line\n",
    "    \"\"\"\n",
    "    for path in glob('%s/*.gz' % root):\n",
    "        with gzip.open(path) as fh:\n",
    "            for line in fh:\n",
    "                data = ujson.loads(line)\n",
    "                yield TextLine.from_json_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLine:\n",
    "    \n",
    "    @classmethod\n",
    "    def from_json_dict(cls, d):\n",
    "        \"\"\"Build from raw JSON line dict.\n",
    "        \"\"\"\n",
    "        title = d.pop('title')\n",
    "        label = d.pop('label')\n",
    "        return cls(title, label, d)\n",
    "\n",
    "    def __init__(self, text, label, metadata=None):\n",
    "        self.text = text.lower()\n",
    "        self.label = label\n",
    "        self.metadata = metadata or {}\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        pattern = '{cls_name}<{char_count} chars, {label}>'\n",
    "\n",
    "        return pattern.format(\n",
    "            cls_name=self.__class__.__name__,\n",
    "            char_count=len(self.text),\n",
    "            label=self.label,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus(Dataset):\n",
    "\n",
    "    def __init__(self, root, skim=None):\n",
    "        \"\"\"Read lines.\n",
    "        \"\"\"\n",
    "        logger.info('Parsing line corpus.')\n",
    "        lines_iter = islice(read_json_gz_lines(root), skim)\n",
    "        self.lines = list(tqdm(lines_iter))\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        pattern = '{cls_name}<{line_count} lines>'\n",
    "\n",
    "        return pattern.format(\n",
    "            cls_name=self.__class__.__name__,\n",
    "            line_count=len(self),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.lines[i]\n",
    "\n",
    "    def char_counts(self):\n",
    "        \"\"\"Collect all char -> count.\n",
    "        \"\"\"\n",
    "        logger.info('Gathering char counts.')\n",
    "\n",
    "        counts = Counter()\n",
    "        for line in tqdm(self):\n",
    "            counts.update(list(line.text))\n",
    "\n",
    "        return counts\n",
    "\n",
    "    def label_counts(self):\n",
    "        \"\"\"Label -> count.\n",
    "        \"\"\"\n",
    "        logger.info('Gathering label counts.')\n",
    "\n",
    "        counts = Counter()\n",
    "        for line in tqdm(self):\n",
    "            counts[line.label] += 1\n",
    "\n",
    "        return counts\n",
    "\n",
    "    def labels(self):\n",
    "        counts = self.label_counts()\n",
    "        return [label for label, _ in counts.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-11 10:32:42,088 | INFO : Parsing line corpus.\n",
      "10000it [00:00, 123953.94it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus('../data/b13-texts.json/', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharEmbedding(nn.Embedding):\n",
    "\n",
    "    def __init__(self, vocab, embed_dim=15):\n",
    "        \"\"\"Set vocab, map s->i.\n",
    "        \"\"\"\n",
    "        self.vocab = vocab\n",
    "        super().__init__(len(self.vocab), embed_dim)\n",
    "\n",
    "    def chars_to_idxs(self, chars):\n",
    "        \"\"\"Map characters to embedding indexes.\n",
    "        \"\"\"\n",
    "        idxs = [self.vocab.stoi[c] for c in chars]\n",
    "\n",
    "        return torch.LongTensor(idxs).type(itype)\n",
    "\n",
    "    def forward(self, texts):\n",
    "        \"\"\"Batch-embed token chars.\n",
    "\n",
    "        Args:\n",
    "            texts (list<str>)\n",
    "        \"\"\"\n",
    "        sizes = [len(t) for t in texts]\n",
    "        chars = list(chain(*texts))\n",
    "        \n",
    "        # Map chars -> indexes.\n",
    "        x = torch.cat([self.chars_to_idxs(t) for t in chars])\n",
    "\n",
    "        # Embed.\n",
    "        x = super().forward(x)\n",
    "        \n",
    "        return group_by_sizes(x, sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size=1024, num_layers=2):\n",
    "        \"\"\"Initialize LSTM.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    @property\n",
    "    def out_dim(self):\n",
    "        return self.lstm.hidden_size * 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Sort, pack, encode, reorder.\n",
    "\n",
    "        Args:\n",
    "            x (list<Tensor>): Variable-length embedding tensors.\n",
    "        \"\"\"\n",
    "        sizes = list(map(len, x))\n",
    "\n",
    "        # Pad + LSTM.\n",
    "        x = rnn.pad_sequence(x, batch_first=True)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Unpad.\n",
    "        return [s[:size] for s, size in zip(x, sizes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLM(nn.Module):\n",
    "\n",
    "    def __init__(self, char_counts, lstm_dim=200, embed_dim=100):\n",
    "        \"\"\"Initialize encoders + clf.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab = Vocab(char_counts)\n",
    "\n",
    "        self.embed_chars = CharEmbedding(self.vocab)\n",
    "\n",
    "        self.encode_f = LineEncoder(self.embed_chars.embedding_dim, lstm_dim)\n",
    "        self.encode_b = LineEncoder(self.embed_chars.embedding_dim, lstm_dim)\n",
    "\n",
    "        self.merge = nn.Linear(lstm_dim*2, embed_dim)\n",
    "\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Linear(embed_dim, len(self.vocab)),\n",
    "            nn.LogSoftmax(1),\n",
    "        )\n",
    "\n",
    "    def batch_iter(self, lines_iter, size=50):\n",
    "        \"\"\"Generate batches of line -> targets.\n",
    "        \"\"\"\n",
    "        for lines in chunked_iter(lines_iter, size):\n",
    "            \n",
    "            yt_idx = [self.vocab.stoi[c] for line in lines for c in line.text]\n",
    "            yt = torch.LongTensor(yt_idx).type(itype)\n",
    "\n",
    "            yield lines, yt\n",
    "\n",
    "    def encode(self, lines):\n",
    "        \"\"\"Embed lines.\n",
    "\n",
    "        Args:\n",
    "            lines (list<str>)\n",
    "        \"\"\"\n",
    "        # Add start/end spaces.\n",
    "        texts = [f' {line.text} ' for line in lines]\n",
    "        \n",
    "        x = self.embed_chars(texts)\n",
    "\n",
    "        # Forward LSTM.\n",
    "        xf = self.encode_f(x)\n",
    "\n",
    "        # Backward LSTM.\n",
    "        x_rev = [xi.flip(0) for xi in x]\n",
    "        xb = self.encode_b(x_rev)\n",
    "        xb = [xi.flip(0) for xi in xb]\n",
    "\n",
    "        # Cat [forward n-1, backward n+1] states for each token.\n",
    "        x = [\n",
    "            torch.cat([xfi[:-2], xbi[2:]], dim=1)\n",
    "            for xfi, xbi in zip(xf, xb)\n",
    "        ]\n",
    "\n",
    "        x = torch.cat(x, dim=0)\n",
    "        x = self.merge(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    def __init__(self, corpus_root, lr=1e-4, batch_size=50, test_size=10000,\n",
    "        eval_every=100000, corpus_kwargs=None, model_kwargs=None):\n",
    "\n",
    "        self.corpus = Corpus(corpus_root, **(corpus_kwargs or {}))\n",
    "\n",
    "        char_counts = self.corpus.char_counts()\n",
    "\n",
    "        self.model = CharLM(char_counts, **(model_kwargs or {}))\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.eval_every = eval_every\n",
    "\n",
    "        self.train_lines, self.val_lines = train_test_split(\n",
    "            self.corpus.lines, test_size=test_size)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.model.cuda()\n",
    "\n",
    "    def train(self, epochs=10):\n",
    "        \"\"\"Train for N epochs.\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            self.train_epoch(epoch)\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "\n",
    "        logger.info('Epoch %d' % epoch)\n",
    "\n",
    "        lines_iter = tqdm(self.train_lines)\n",
    "\n",
    "        batches = self.model.batch_iter(lines_iter, self.batch_size)\n",
    "\n",
    "        batch_losses = []\n",
    "        eval_n = 0\n",
    "        for lines, yt in batches:\n",
    "\n",
    "            self.model.train()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            embeds = self.model.encode(lines)\n",
    "            yp = self.model.predict(embeds)\n",
    "\n",
    "            loss = F.nll_loss(yp, yt)\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "            n = math.floor(lines_iter.n / self.eval_every)\n",
    "\n",
    "            if n > eval_n:\n",
    "                self.log_metrics(batch_losses)\n",
    "                eval_n = n\n",
    "\n",
    "        self.log_metrics(batch_losses)\n",
    "\n",
    "    def log_metrics(self, batch_losses, n=100):\n",
    "        logger.info('Train loss: %f' % np.mean(batch_losses[-n:]))\n",
    "        self.log_val_metrics()\n",
    "\n",
    "    def log_val_metrics(self):\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        lines_iter = tqdm(self.val_lines)\n",
    "\n",
    "        batches = self.model.batch_iter(lines_iter, self.batch_size)\n",
    "\n",
    "        losses = []\n",
    "        for lines, yt in batches:\n",
    "\n",
    "            embeds = self.model.encode(lines)\n",
    "            yp = self.model.predict(embeds)\n",
    "\n",
    "            losses.append(F.nll_loss(yp, yt).item())\n",
    "\n",
    "        logger.info('Val loss: %f' % np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-11 10:32:51,576 | INFO : Parsing line corpus.\n",
      "10000it [00:00, 59231.46it/s]\n",
      "2018-12-11 10:32:51,748 | INFO : Gathering char counts.\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 142007.46it/s]\n"
     ]
    }
   ],
   "source": [
    "t = Trainer('../data/b13-texts.json/', eval_every=1000, test_size=100, corpus_kwargs=dict(skim=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-11 10:32:52,431 | INFO : Epoch 0\n",
      " 10%|█         | 1000/9900 [00:30<04:02, 36.74it/s]2018-12-11 10:33:24,018 | INFO : Train loss: 4.440156\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 125.12it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 124.27it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:33:24,834 | INFO : Val loss: 4.408150\n",
      " 20%|██        | 2000/9900 [01:00<03:37, 36.33it/s]2018-12-11 10:33:54,382 | INFO : Train loss: 4.392431\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 124.02it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 123.94it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:33:55,195 | INFO : Val loss: 4.205162\n",
      " 30%|███       | 3000/9900 [01:30<03:26, 33.35it/s]2018-12-11 10:34:23,748 | INFO : Train loss: 4.180735\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 126.10it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 125.52it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:34:24,553 | INFO : Val loss: 3.323081\n",
      " 40%|████      | 4000/9900 [01:59<03:04, 31.96it/s]2018-12-11 10:34:53,222 | INFO : Train loss: 3.942688\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 123.27it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 122.18it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:34:54,051 | INFO : Val loss: 3.124297\n",
      " 51%|█████     | 5000/9900 [02:31<02:11, 37.18it/s]2018-12-11 10:35:25,717 | INFO : Train loss: 3.773174\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 119.65it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 118.77it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:35:26,575 | INFO : Val loss: 3.080188\n",
      " 61%|██████    | 6000/9900 [03:01<01:54, 33.96it/s]2018-12-11 10:35:55,609 | INFO : Train loss: 3.505421\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 115.82it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 115.34it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:35:56,485 | INFO : Val loss: 3.069755\n",
      " 71%|███████   | 7000/9900 [03:32<01:30, 32.18it/s]2018-12-11 10:36:26,457 | INFO : Train loss: 3.253069\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 111.47it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.88it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:36:27,356 | INFO : Val loss: 3.062851\n",
      " 81%|████████  | 8000/9900 [04:03<00:59, 31.78it/s]2018-12-11 10:36:57,478 | INFO : Train loss: 3.119916\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 111.32it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.10it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:36:58,386 | INFO : Val loss: 3.057802\n",
      " 91%|█████████ | 9000/9900 [04:32<00:24, 36.72it/s]2018-12-11 10:37:27,023 | INFO : Train loss: 3.092038\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 112.32it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.44it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:37:27,919 | INFO : Val loss: 3.053577\n",
      "100%|██████████| 9900/9900 [04:59<00:00, 36.14it/s]\n",
      "2018-12-11 10:37:51,941 | INFO : Train loss: 3.082878\n",
      "100%|██████████| 100/100 [00:00<00:00, 107.68it/s]\n",
      "2018-12-11 10:37:52,870 | INFO : Val loss: 3.050389\n",
      "2018-12-11 10:37:52,922 | INFO : Epoch 1\n",
      " 10%|█         | 1000/9900 [00:32<04:17, 34.60it/s]2018-12-11 10:38:26,757 | INFO : Train loss: 3.064113\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 112.18it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.46it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:38:27,650 | INFO : Val loss: 3.044470\n",
      " 20%|██        | 2000/9900 [01:04<03:53, 33.89it/s]2018-12-11 10:38:59,046 | INFO : Train loss: 3.059137\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 109.45it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.75it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:38:59,963 | INFO : Val loss: 3.035375\n",
      " 30%|███       | 3000/9900 [01:36<03:38, 31.52it/s]2018-12-11 10:39:30,382 | INFO : Train loss: 3.056205\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.23it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.08it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:39:31,274 | INFO : Val loss: 3.025202\n",
      " 40%|████      | 4000/9900 [02:07<03:24, 28.84it/s]2018-12-11 10:40:01,682 | INFO : Train loss: 3.050413\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 111.04it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.19it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:40:02,588 | INFO : Val loss: 3.009302\n",
      " 51%|█████     | 5000/9900 [02:41<02:18, 35.39it/s]2018-12-11 10:40:35,668 | INFO : Train loss: 3.044044\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 111.52it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.90it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:40:36,586 | INFO : Val loss: 2.990643\n",
      " 61%|██████    | 6000/9900 [03:12<01:58, 32.78it/s]2018-12-11 10:41:06,344 | INFO : Train loss: 3.031170\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 111.51it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.10it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:41:07,252 | INFO : Val loss: 2.967464\n",
      " 71%|███████   | 7000/9900 [03:43<01:30, 32.02it/s]2018-12-11 10:41:37,571 | INFO : Train loss: 3.014301\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 112.40it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.30it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:41:38,469 | INFO : Val loss: 2.944060\n",
      " 81%|████████  | 8000/9900 [04:13<00:58, 32.38it/s]2018-12-11 10:42:08,223 | INFO : Train loss: 2.995720\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.51it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.24it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:42:09,116 | INFO : Val loss: 2.919597\n",
      " 91%|█████████ | 9000/9900 [04:43<00:24, 36.24it/s]2018-12-11 10:42:37,669 | INFO : Train loss: 2.976436\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.49it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.18it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:42:38,560 | INFO : Val loss: 2.898361\n",
      "100%|██████████| 9900/9900 [05:09<00:00, 36.47it/s]\n",
      "2018-12-11 10:43:02,303 | INFO : Train loss: 2.959052\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.97it/s]\n",
      "2018-12-11 10:43:03,211 | INFO : Val loss: 2.880537\n",
      "2018-12-11 10:43:03,265 | INFO : Epoch 2\n",
      " 10%|█         | 1000/9900 [00:32<04:17, 34.60it/s]2018-12-11 10:43:37,448 | INFO : Train loss: 2.898418\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 112.12it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.34it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:43:38,349 | INFO : Val loss: 2.865211\n",
      " 20%|██        | 2000/9900 [01:04<03:54, 33.73it/s]2018-12-11 10:44:09,427 | INFO : Train loss: 2.887016\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.41it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.42it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:44:10,329 | INFO : Val loss: 2.841710\n",
      " 30%|███       | 3000/9900 [01:36<03:51, 29.87it/s]2018-12-11 10:44:41,184 | INFO : Train loss: 2.880594\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 106.96it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:01<00:00, 102.58it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:44:42,192 | INFO : Val loss: 2.826858\n",
      " 40%|████      | 4000/9900 [02:07<03:15, 30.21it/s]2018-12-11 10:45:11,919 | INFO : Train loss: 2.871918\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 111.33it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.21it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:45:12,812 | INFO : Val loss: 2.807649\n",
      " 51%|█████     | 5000/9900 [02:41<02:14, 36.53it/s]2018-12-11 10:45:45,871 | INFO : Train loss: 2.863060\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 118.43it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 116.36it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:45:46,752 | INFO : Val loss: 2.792246\n",
      " 61%|██████    | 6000/9900 [03:12<01:57, 33.15it/s]2018-12-11 10:46:16,955 | INFO : Train loss: 2.846520\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 114.02it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 114.04it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:46:17,837 | INFO : Val loss: 2.780529\n",
      " 71%|███████   | 7000/9900 [03:43<01:29, 32.42it/s]2018-12-11 10:46:48,369 | INFO : Train loss: 2.829753\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 98.45it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 100.30it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:46:49,360 | INFO : Val loss: 2.760448\n",
      " 81%|████████  | 8000/9900 [04:15<01:00, 31.54it/s]2018-12-11 10:47:19,835 | INFO : Train loss: 2.813169\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 102.66it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 104.82it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:47:20,781 | INFO : Val loss: 2.741082\n",
      " 91%|█████████ | 9000/9900 [04:47<00:29, 30.74it/s]2018-12-11 10:47:55,315 | INFO : Train loss: 2.797819\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:01<00:01, 41.67it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:01<00:00, 46.77it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:47:57,294 | INFO : Val loss: 2.723316\n",
      "100%|██████████| 9900/9900 [05:23<00:00, 34.49it/s]\n",
      "2018-12-11 10:48:26,855 | INFO : Train loss: 2.784978\n",
      "100%|██████████| 100/100 [00:00<00:00, 108.78it/s]\n",
      "2018-12-11 10:48:27,782 | INFO : Val loss: 2.707640\n",
      "2018-12-11 10:48:27,838 | INFO : Epoch 3\n",
      " 10%|█         | 1000/9900 [00:33<04:30, 32.87it/s]2018-12-11 10:49:03,150 | INFO : Train loss: 2.738143\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 100.82it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 102.97it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:49:04,119 | INFO : Val loss: 2.687144\n",
      " 20%|██        | 2000/9900 [01:06<03:52, 33.99it/s]2018-12-11 10:49:35,710 | INFO : Train loss: 2.722264\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 114.47it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 114.22it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:49:36,594 | INFO : Val loss: 2.666005\n",
      " 30%|███       | 3000/9900 [01:37<03:36, 31.87it/s]2018-12-11 10:50:06,903 | INFO : Train loss: 2.713748\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.14it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.20it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:50:07,793 | INFO : Val loss: 2.646603\n",
      " 40%|████      | 4000/9900 [02:09<03:20, 29.48it/s]2018-12-11 10:50:38,619 | INFO : Train loss: 2.702991\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 108.67it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.48it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:50:39,520 | INFO : Val loss: 2.626607\n",
      " 51%|█████     | 5000/9900 [02:43<02:15, 36.08it/s]2018-12-11 10:51:12,710 | INFO : Train loss: 2.692245\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 109.84it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.48it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:51:13,619 | INFO : Val loss: 2.607476\n",
      " 61%|██████    | 6000/9900 [03:14<02:01, 32.06it/s]2018-12-11 10:51:43,722 | INFO : Train loss: 2.671495\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 111.35it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.31it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:51:44,627 | INFO : Val loss: 2.594337\n",
      " 71%|███████   | 7000/9900 [03:45<01:31, 31.75it/s]2018-12-11 10:52:15,238 | INFO : Train loss: 2.652842\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 112.31it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.94it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:52:16,140 | INFO : Val loss: 2.574972\n",
      " 81%|████████  | 8000/9900 [04:17<00:59, 31.84it/s]2018-12-11 10:52:46,715 | INFO : Train loss: 2.635371\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 109.92it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.77it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:52:47,619 | INFO : Val loss: 2.556428\n",
      " 91%|█████████ | 9000/9900 [04:46<00:25, 35.77it/s]2018-12-11 10:53:16,360 | INFO : Train loss: 2.619823\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 112.21it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.28it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:53:17,258 | INFO : Val loss: 2.541460\n",
      "100%|██████████| 9900/9900 [05:13<00:00, 35.94it/s]\n",
      "2018-12-11 10:53:41,324 | INFO : Train loss: 2.608167\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.11it/s]\n",
      "2018-12-11 10:53:42,238 | INFO : Val loss: 2.527631\n",
      "2018-12-11 10:53:42,288 | INFO : Epoch 4\n",
      " 10%|█         | 1000/9900 [00:32<04:19, 34.26it/s]2018-12-11 10:54:16,115 | INFO : Train loss: 2.571623\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 110.19it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.16it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:54:17,015 | INFO : Val loss: 2.509894\n",
      " 20%|██        | 2000/9900 [01:04<03:47, 34.71it/s]2018-12-11 10:54:48,053 | INFO : Train loss: 2.555874\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 112.86it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.84it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:54:48,944 | INFO : Val loss: 2.493184\n",
      " 30%|███       | 3000/9900 [01:36<03:39, 31.44it/s]2018-12-11 10:55:19,661 | INFO : Train loss: 2.549655\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.56it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.71it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:55:20,558 | INFO : Val loss: 2.478955\n",
      " 40%|████      | 4000/9900 [02:07<03:16, 30.09it/s]2018-12-11 10:55:51,064 | INFO : Train loss: 2.541739\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 107.95it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.01it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:55:51,981 | INFO : Val loss: 2.463234\n",
      " 51%|█████     | 5000/9900 [02:41<02:16, 35.95it/s]2018-12-11 10:56:25,422 | INFO : Train loss: 2.533595\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 108.94it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.38it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:56:26,346 | INFO : Val loss: 2.449192\n",
      " 61%|██████    | 6000/9900 [03:13<02:00, 32.28it/s]2018-12-11 10:56:56,878 | INFO : Train loss: 2.518509\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 109.64it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.57it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:56:57,797 | INFO : Val loss: 2.438740\n",
      " 71%|███████   | 7000/9900 [03:44<01:29, 32.41it/s]2018-12-11 10:57:28,027 | INFO : Train loss: 2.505376\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.39it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.90it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:57:28,935 | INFO : Val loss: 2.426281\n",
      " 81%|████████  | 8000/9900 [04:15<01:01, 30.87it/s]2018-12-11 10:57:59,126 | INFO : Train loss: 2.493545\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.70it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.39it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:58:00,016 | INFO : Val loss: 2.410890\n",
      " 91%|█████████ | 9000/9900 [04:44<00:24, 37.15it/s]2018-12-11 10:58:28,123 | INFO : Train loss: 2.482467\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 109.51it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.22it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:58:29,033 | INFO : Val loss: 2.397114\n",
      "100%|██████████| 9900/9900 [05:10<00:00, 36.87it/s]\n",
      "2018-12-11 10:58:52,925 | INFO : Train loss: 2.474407\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.38it/s]\n",
      "2018-12-11 10:58:53,827 | INFO : Val loss: 2.386689\n",
      "2018-12-11 10:58:53,878 | INFO : Epoch 5\n",
      " 10%|█         | 1000/9900 [00:31<04:15, 34.77it/s]2018-12-11 10:59:27,098 | INFO : Train loss: 2.448472\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 106.94it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 107.57it/s]\u001b[A\n",
      "\u001b[A2018-12-11 10:59:28,030 | INFO : Val loss: 2.374375\n",
      " 20%|██        | 2000/9900 [01:04<03:51, 34.15it/s]2018-12-11 10:59:59,504 | INFO : Train loss: 2.434848\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 109.60it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 107.95it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:00:00,447 | INFO : Val loss: 2.362181\n",
      " 30%|███       | 3000/9900 [01:35<03:40, 31.25it/s]2018-12-11 11:00:31,154 | INFO : Train loss: 2.430363\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 106.43it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 107.31it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:00:32,087 | INFO : Val loss: 2.352001\n",
      " 40%|████      | 4000/9900 [02:06<03:14, 30.28it/s]2018-12-11 11:01:01,949 | INFO : Train loss: 2.423963\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 108.82it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.40it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:01:02,867 | INFO : Val loss: 2.339627\n",
      " 51%|█████     | 5000/9900 [02:40<02:15, 36.06it/s]2018-12-11 11:01:36,172 | INFO : Train loss: 2.417829\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 112.07it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.96it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:01:37,073 | INFO : Val loss: 2.330050\n",
      " 61%|██████    | 6000/9900 [03:11<01:58, 32.89it/s]2018-12-11 11:02:06,718 | INFO : Train loss: 2.406611\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.27it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.82it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:02:07,600 | INFO : Val loss: 2.323580\n",
      " 71%|███████   | 7000/9900 [03:44<01:36, 29.99it/s]2018-12-11 11:02:39,885 | INFO : Train loss: 2.397287\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 104.57it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 105.24it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:02:40,837 | INFO : Val loss: 2.313907\n",
      " 81%|████████  | 8000/9900 [04:17<01:06, 28.40it/s]2018-12-11 11:03:13,343 | INFO : Train loss: 2.388518\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 102.26it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 102.84it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:03:14,317 | INFO : Val loss: 2.302178\n",
      " 91%|█████████ | 9000/9900 [04:49<00:27, 32.36it/s]2018-12-11 11:03:45,861 | INFO : Train loss: 2.381140\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 87.08it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:01<00:00, 87.86it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:03:47,002 | INFO : Val loss: 2.291291\n",
      "100%|██████████| 9900/9900 [05:18<00:00, 36.25it/s]\n",
      "2018-12-11 11:04:11,954 | INFO : Train loss: 2.375972\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.91it/s]\n",
      "2018-12-11 11:04:12,863 | INFO : Val loss: 2.283537\n",
      "2018-12-11 11:04:12,908 | INFO : Epoch 6\n",
      " 10%|█         | 1000/9900 [00:32<04:19, 34.31it/s]2018-12-11 11:04:47,022 | INFO : Train loss: 2.359817\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 114.23it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 114.24it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:04:47,904 | INFO : Val loss: 2.275065\n",
      " 20%|██        | 2000/9900 [01:04<03:46, 34.83it/s]2018-12-11 11:05:18,705 | INFO : Train loss: 2.346696\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.59it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.39it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:05:19,594 | INFO : Val loss: 2.265113\n",
      " 30%|███       | 3000/9900 [01:35<03:36, 31.84it/s]2018-12-11 11:05:49,741 | INFO : Train loss: 2.343730\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.81it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 114.09it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:05:50,623 | INFO : Val loss: 2.256691\n",
      " 40%|████      | 4000/9900 [02:06<03:14, 30.30it/s]2018-12-11 11:06:20,776 | INFO : Train loss: 2.339078\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 111.23it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.59it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:06:21,663 | INFO : Val loss: 2.247649\n",
      " 51%|█████     | 5000/9900 [02:40<02:14, 36.56it/s]2018-12-11 11:06:54,858 | INFO : Train loss: 2.334078\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.60it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.73it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:06:55,749 | INFO : Val loss: 2.240947\n",
      " 61%|██████    | 6000/9900 [03:11<01:56, 33.48it/s]2018-12-11 11:07:25,402 | INFO : Train loss: 2.325945\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.15it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.06it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:07:26,294 | INFO : Val loss: 2.235854\n",
      " 71%|███████   | 7000/9900 [03:42<01:31, 31.83it/s]2018-12-11 11:07:56,778 | INFO : Train loss: 2.318985\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.05it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.10it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:07:57,668 | INFO : Val loss: 2.227106\n",
      " 81%|████████  | 8000/9900 [04:13<00:59, 31.80it/s]2018-12-11 11:08:27,699 | INFO : Train loss: 2.311747\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 111.46it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.94it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:08:28,609 | INFO : Val loss: 2.218937\n",
      " 91%|█████████ | 9000/9900 [04:42<00:24, 37.19it/s]2018-12-11 11:08:56,766 | INFO : Train loss: 2.306036\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 112.19it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.66it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:08:57,657 | INFO : Val loss: 2.209505\n",
      "100%|██████████| 9900/9900 [05:08<00:00, 36.04it/s]\n",
      "2018-12-11 11:09:21,296 | INFO : Train loss: 2.302922\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.74it/s]\n",
      "2018-12-11 11:09:22,201 | INFO : Val loss: 2.203878\n",
      "2018-12-11 11:09:22,252 | INFO : Epoch 7\n",
      " 10%|█         | 1000/9900 [00:32<04:16, 34.63it/s]2018-12-11 11:09:55,923 | INFO : Train loss: 2.287369\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 109.48it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.71it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:09:56,826 | INFO : Val loss: 2.198142\n",
      " 20%|██        | 2000/9900 [01:04<03:52, 34.00it/s]2018-12-11 11:10:28,586 | INFO : Train loss: 2.275786\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 107.31it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 107.17it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:10:29,526 | INFO : Val loss: 2.187892\n",
      " 30%|███       | 3000/9900 [01:36<03:39, 31.45it/s]2018-12-11 11:11:00,008 | INFO : Train loss: 2.274418\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 110.92it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 107.11it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:11:00,969 | INFO : Val loss: 2.183462\n",
      " 40%|████      | 4000/9900 [02:07<03:15, 30.22it/s]2018-12-11 11:11:30,902 | INFO : Train loss: 2.270646\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 112.98it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.49it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:11:31,787 | INFO : Val loss: 2.173114\n",
      " 51%|█████     | 5000/9900 [02:41<02:15, 36.22it/s]2018-12-11 11:12:04,972 | INFO : Train loss: 2.266326\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 110.33it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.01it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:12:05,896 | INFO : Val loss: 2.168035\n",
      " 61%|██████    | 6000/9900 [03:12<02:00, 32.26it/s]2018-12-11 11:12:35,946 | INFO : Train loss: 2.260093\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 111.59it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.00it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:12:36,857 | INFO : Val loss: 2.161412\n",
      " 71%|███████   | 7000/9900 [03:43<01:29, 32.46it/s]2018-12-11 11:13:07,548 | INFO : Train loss: 2.254871\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 108.75it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 104.07it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:13:08,544 | INFO : Val loss: 2.156139\n",
      " 81%|████████  | 8000/9900 [04:14<00:58, 32.29it/s]2018-12-11 11:13:38,653 | INFO : Train loss: 2.248916\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.95it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.60it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:13:39,540 | INFO : Val loss: 2.147842\n",
      " 91%|█████████ | 9000/9900 [04:44<00:24, 36.36it/s]2018-12-11 11:14:08,410 | INFO : Train loss: 2.244635\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 112.27it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.60it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:14:09,302 | INFO : Val loss: 2.139851\n",
      "100%|██████████| 9900/9900 [05:10<00:00, 36.64it/s]\n",
      "2018-12-11 11:14:32,999 | INFO : Train loss: 2.242394\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.76it/s]\n",
      "2018-12-11 11:14:33,892 | INFO : Val loss: 2.136941\n",
      "2018-12-11 11:14:33,944 | INFO : Epoch 8\n",
      " 10%|█         | 1000/9900 [00:32<04:13, 35.06it/s]2018-12-11 11:15:07,556 | INFO : Train loss: 2.231234\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 99.74it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 104.00it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:15:08,501 | INFO : Val loss: 2.128895\n",
      " 20%|██        | 2000/9900 [01:05<04:04, 32.34it/s]2018-12-11 11:15:40,778 | INFO : Train loss: 2.221942\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 105.59it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 104.88it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:15:41,742 | INFO : Val loss: 2.120857\n",
      " 30%|███       | 3000/9900 [01:37<03:46, 30.44it/s]2018-12-11 11:16:12,563 | INFO : Train loss: 2.219617\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 109.54it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 107.83it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:16:13,506 | INFO : Val loss: 2.118777\n",
      " 40%|████      | 4000/9900 [02:08<03:15, 30.18it/s]2018-12-11 11:16:43,699 | INFO : Train loss: 2.216531\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 110.51it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.18it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:16:44,600 | INFO : Val loss: 2.109016\n",
      " 51%|█████     | 5000/9900 [02:42<02:12, 36.95it/s]2018-12-11 11:17:17,619 | INFO : Train loss: 2.212018\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.81it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.35it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:17:18,515 | INFO : Val loss: 2.103546\n",
      " 61%|██████    | 6000/9900 [03:13<01:58, 32.78it/s]2018-12-11 11:17:48,496 | INFO : Train loss: 2.206343\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 107.23it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 108.03it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:17:49,422 | INFO : Val loss: 2.098638\n",
      " 71%|███████   | 7000/9900 [03:44<01:30, 32.14it/s]2018-12-11 11:18:19,873 | INFO : Train loss: 2.201536\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 111.45it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.20it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:18:20,794 | INFO : Val loss: 2.091903\n",
      " 81%|████████  | 8000/9900 [04:15<00:59, 31.75it/s]2018-12-11 11:18:50,796 | INFO : Train loss: 2.195956\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 111.06it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.33it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:18:51,700 | INFO : Val loss: 2.086406\n",
      " 91%|█████████ | 9000/9900 [04:44<00:24, 36.61it/s]2018-12-11 11:19:20,389 | INFO : Train loss: 2.191483\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 109.81it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.11it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:19:21,301 | INFO : Val loss: 2.079014\n",
      "100%|██████████| 9900/9900 [05:11<00:00, 36.16it/s]\n",
      "2018-12-11 11:19:45,100 | INFO : Train loss: 2.190057\n",
      "100%|██████████| 100/100 [00:00<00:00, 101.66it/s]\n",
      "2018-12-11 11:19:46,103 | INFO : Val loss: 2.077569\n",
      "2018-12-11 11:19:46,157 | INFO : Epoch 9\n",
      " 10%|█         | 1000/9900 [00:32<04:19, 34.35it/s]2018-12-11 11:20:20,069 | INFO : Train loss: 2.179729\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.36it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.50it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:20:20,956 | INFO : Val loss: 2.069422\n",
      " 20%|██        | 2000/9900 [01:04<03:53, 33.90it/s]2018-12-11 11:20:52,471 | INFO : Train loss: 2.172163\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 107.35it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 108.74it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:20:53,388 | INFO : Val loss: 2.061959\n",
      " 30%|███       | 3000/9900 [01:36<03:43, 30.83it/s]2018-12-11 11:21:24,319 | INFO : Train loss: 2.170224\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 119.38it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.60it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:21:25,185 | INFO : Val loss: 2.057900\n",
      " 40%|████      | 4000/9900 [02:08<03:17, 29.91it/s]2018-12-11 11:21:55,568 | INFO : Train loss: 2.166920\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 113.52it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.69it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:21:56,455 | INFO : Val loss: 2.050372\n",
      " 51%|█████     | 5000/9900 [02:41<02:12, 36.87it/s]2018-12-11 11:22:29,430 | INFO : Train loss: 2.162588\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 103.20it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 105.95it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:22:30,368 | INFO : Val loss: 2.045753\n",
      " 61%|██████    | 6000/9900 [03:13<01:59, 32.76it/s]2018-12-11 11:23:00,893 | INFO : Train loss: 2.157823\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 109.32it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.41it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:23:01,813 | INFO : Val loss: 2.041190\n",
      " 71%|███████   | 7000/9900 [03:44<01:29, 32.31it/s]2018-12-11 11:23:32,352 | INFO : Train loss: 2.152301\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 110.70it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.28it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:23:33,254 | INFO : Val loss: 2.036875\n",
      " 81%|████████  | 8000/9900 [04:15<00:58, 32.23it/s]2018-12-11 11:24:03,223 | INFO : Train loss: 2.146592\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 111.94it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.33it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:24:04,117 | INFO : Val loss: 2.029884\n",
      " 91%|█████████ | 9000/9900 [04:44<00:24, 37.13it/s]2018-12-11 11:24:32,418 | INFO : Train loss: 2.143176\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:00<00:00, 108.11it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 109.13it/s]\u001b[A\n",
      "\u001b[A2018-12-11 11:24:33,335 | INFO : Val loss: 2.023619\n",
      "100%|██████████| 9900/9900 [05:11<00:00, 36.23it/s]\n",
      "2018-12-11 11:24:57,211 | INFO : Train loss: 2.141968\n",
      "100%|██████████| 100/100 [00:00<00:00, 101.74it/s]\n",
      "2018-12-11 11:24:58,180 | INFO : Val loss: 2.021353\n"
     ]
    }
   ],
   "source": [
    "t.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
