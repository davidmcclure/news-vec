{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gzip\n",
    "import ujson\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from itertools import islice\n",
    "from tqdm import tqdm\n",
    "from boltons.iterutils import windowed\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from news_vec import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "mpl.style.use('seaborn-muted')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line:\n",
    "\n",
    "    def __init__(self, tokens, label, lower=True):\n",
    "        self.tokens = [t.lower() for t in tokens] if lower else tokens\n",
    "        self.label = label\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        pattern = '{cls_name}<{token_count} tokens -> {label}>'\n",
    "\n",
    "        return pattern.format(\n",
    "            cls_name=self.__class__.__name__,\n",
    "            token_count=len(self.tokens),\n",
    "            label=self.label,\n",
    "        )\n",
    "    \n",
    "    def ngrams_iter(self, n, vocab=None):\n",
    "        for ng in windowed(self.tokens, n):\n",
    "            if not vocab or ng in vocab:\n",
    "                yield ng\n",
    "    \n",
    "    def features_iter(self, vocab):\n",
    "        yield from Counter(self.ngrams_iter(1, vocab)).items()\n",
    "        \n",
    "    def x(self, vocab):\n",
    "        return dict(self.features_iter(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_lines(root, lower=True):\n",
    "    \"\"\"Generate links from a JSON corpus.\n",
    "\n",
    "    Yields: list<str>\n",
    "    \"\"\"\n",
    "    for path in glob('%s/*.gz' % root):\n",
    "        with gzip.open(path) as fh:\n",
    "            for line in fh:\n",
    "\n",
    "                data = ujson.loads(line)\n",
    "\n",
    "                tokens = data.get('tokens')\n",
    "\n",
    "                if not tokens:\n",
    "                    continue\n",
    "\n",
    "                yield Line(tokens, data['label'], lower=lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "\n",
    "    def __init__(self, root, skim=None, lower=True):\n",
    "        \"\"\"Read lines.\n",
    "        \"\"\"\n",
    "        logger.info('Parsing line corpus.')\n",
    "\n",
    "        lines_iter = islice(read_json_lines(root, lower), skim)\n",
    "\n",
    "        self.lines = list(tqdm(lines_iter))\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        pattern = '{cls_name}<{line_count} lines>'\n",
    "\n",
    "        return pattern.format(\n",
    "            cls_name=self.__class__.__name__,\n",
    "            line_count=len(self),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.lines)\n",
    "    \n",
    "    def ngram_counts(self, n):\n",
    "        \"\"\"Collect all ngram -> count.\n",
    "        \"\"\"\n",
    "        logger.info('Gathering %d-gram counts.' % n)\n",
    "\n",
    "        counts = Counter()\n",
    "        for line in tqdm(self):\n",
    "            counts.update(line.ngrams_iter(n))\n",
    "\n",
    "        return counts\n",
    "\n",
    "    def topk_ngrams(self, n, k):\n",
    "        counts = self.ngram_counts(n)\n",
    "        return [ng for ng, _ in counts.most_common(k)]\n",
    "    \n",
    "    def x_iter(self, vocab):\n",
    "        for line in tqdm(self):\n",
    "            yield line.x(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-28 13:38:31,839 | INFO : Parsing line corpus.\n",
      "2123078it [00:26, 80958.91it/s] \n"
     ]
    }
   ],
   "source": [
    "c = Corpus('../data/titles-50k.json/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-28 13:40:08,235 | INFO : Gathering 1-gram counts.\n",
      "100%|██████████| 2123078/2123078 [00:19<00:00, 109424.38it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = set(c.topk_ngrams(1, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2123078/2123078 [00:29<00:00, 71026.99it/s]\n"
     ]
    }
   ],
   "source": [
    "xs = list(c.x_iter(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()\n",
    "X = dv.fit_transform(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2123078x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 15162987 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [line.label for line in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(verbose=True)\n",
    "fit = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "            apnews.com       0.19      0.23      0.21     10158\n",
      "             bbc.co.uk       0.60      0.65      0.62     10034\n",
      "         bloomberg.com       0.24      0.26      0.25     10176\n",
      "         breitbart.com       0.75      0.59      0.66     10087\n",
      "   businessinsider.com       0.35      0.35      0.35     10151\n",
      "          buzzfeed.com       0.38      0.58      0.46     10015\n",
      "                cbc.ca       0.41      0.44      0.43     10098\n",
      "           cbsnews.com       0.25      0.23      0.24     10194\n",
      "              cnbc.com       0.29      0.24      0.26     10135\n",
      "               cnn.com       0.57      0.26      0.36     10118\n",
      "       dailycaller.com       0.99      0.86      0.92      9995\n",
      "          dailykos.com       0.30      0.36      0.33     10221\n",
      "            forbes.com       0.18      0.23      0.20     10133\n",
      "           foxnews.com       0.14      0.07      0.10      9906\n",
      "                ft.com       0.18      0.39      0.25     10076\n",
      "    huffingtonpost.com       0.15      0.07      0.09     10095\n",
      "               inc.com       0.38      0.63      0.48     10059\n",
      "     independent.co.uk       0.21      0.20      0.21     10188\n",
      "               msn.com       0.11      0.02      0.04     10207\n",
      "           nbcnews.com       0.32      0.11      0.17     10226\n",
      "          newsweek.com       0.27      0.25      0.26     10003\n",
      "               npr.org       0.22      0.19      0.21     10027\n",
      "       nydailynews.com       0.40      0.28      0.33     10183\n",
      "            nypost.com       0.15      0.27      0.20     10161\n",
      "           nytimes.com       0.18      0.09      0.12     10030\n",
      "          rawstory.com       0.41      0.42      0.41     10339\n",
      "           reuters.com       0.26      0.34      0.30     10291\n",
      "                rt.com       0.97      0.92      0.95     10054\n",
      "       sputniknews.com       0.30      0.47      0.37     10002\n",
      "       telegraph.co.uk       0.51      0.33      0.40     10098\n",
      "       theguardian.com       0.35      0.27      0.30     10353\n",
      "           thehill.com       0.25      0.31      0.28     10235\n",
      "        thetimes.co.uk       0.18      0.31      0.23      9982\n",
      "              time.com       0.18      0.13      0.15      9861\n",
      "          usatoday.com       0.20      0.23      0.21     10164\n",
      "           variety.com       0.48      0.69      0.56     10267\n",
      "              vice.com       0.31      0.33      0.32     10089\n",
      "washingtonexaminer.com       0.20      0.24      0.22     10135\n",
      "    washingtonpost.com       0.43      0.26      0.33     10081\n",
      "   washingtontimes.com       0.19      0.24      0.21      9885\n",
      "               wsj.com       0.19      0.14      0.16     10008\n",
      "             yahoo.com       0.09      0.01      0.01     10096\n",
      "\n",
      "             micro avg       0.32      0.32      0.32    424616\n",
      "             macro avg       0.33      0.32      0.31    424616\n",
      "          weighted avg       0.33      0.32      0.31    424616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
